{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07912141-32b6-4721-b00a-5593c032e118",
   "metadata": {},
   "source": [
    "# Feature Matrix\n",
    "Purpose of notebook is to enlarge the dataframe and provide the maschine learning model with more <b>context information</b>. <br>\n",
    "e. g. <i>Tokens on the left and right sides and its pos tags, lemmas.</i> <br>\n",
    "Because the tagger in last notebook already provides the pos tags for every token, the prefix, suffix and other features of the token are regarded as surplus and won't be included in the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2af291c5-d754-4f56-9d43-13febebbfc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf2e3e85-1fe6-4520-8ea0-3967ffb0c37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3f6417d-191c-4bc6-9ce9-41bab2f9f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"transitional_data/tagged_train_filled.csv\", keep_default_na=False)\n",
    "df_dev = pd.read_csv(\"transitional_data/tagged_dev_filled.csv\", keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08534c62-4dd4-4258-aedd-dd2976faf30d",
   "metadata": {},
   "source": [
    "<br> to check whether there are still empty cells in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "592717bd-5a7b-4ae3-9023-2ffe048840f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Lemma\"].isnull().tolist().count(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88b5d3af-865b-44b2-907d-24aee6166929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceNR          int64\n",
       "Token              object\n",
       "Label              object\n",
       "standard_tagger    object\n",
       "TreeTagger         object\n",
       "Lemma              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc863def-35d7-4245-927c-44112a244a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceNR          int64\n",
       "Token              string\n",
       "Label              string\n",
       "standard_tagger    string\n",
       "TreeTagger         string\n",
       "Lemma              string\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.Token = df_train.Token.astype(\"string\")\n",
    "df_train.Label = df_train.Label.astype(\"string\")\n",
    "df_train.standard_tagger = df_train.standard_tagger.astype(\"string\")\n",
    "df_train.TreeTagger = df_train.TreeTagger.astype(\"string\")\n",
    "df_train.Lemma = df_train.Lemma.astype(\"string\")\n",
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0a8a2a3-9da3-4741-94b1-6198ee5960c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceNR          int64\n",
       "Token              string\n",
       "Label              string\n",
       "standard_tagger    string\n",
       "TreeTagger         string\n",
       "Lemma              string\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.Token = df_dev.Token.astype(\"string\")\n",
    "df_dev.Label = df_dev.Label.astype(\"string\")\n",
    "df_dev.standard_tagger = df_dev.standard_tagger.astype(\"string\")\n",
    "df_dev.TreeTagger = df_dev.TreeTagger.astype(\"string\")\n",
    "df_dev.Lemma = df_dev.Lemma.astype(\"string\")\n",
    "df_dev.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5972997-6afd-42d8-bd08-91fe6a4ac2cd",
   "metadata": {},
   "source": [
    "<br> number of sentences should start from 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43c716db-727a-4043-8f8f-0c17a7709f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"SentenceNR\"] = df_train[\"SentenceNR\"].apply(lambda x: x+1)\n",
    "df_dev[\"SentenceNR\"] = df_dev[\"SentenceNR\"].apply(lambda x: x+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad691b0-a3f9-4ef1-a989-e1639f496f3d",
   "metadata": {},
   "source": [
    "<br> rearrange the sequence of columns in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1ea139d-6c59-4ac4-b2c1-381250e7a437",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"TokenNR\"] = np.nan\n",
    "df_train = df_train.rename(columns={\"standard_tagger\": \"StandardTagger\"})\n",
    "df_train = df_train[['SentenceNR', 'TokenNR', 'Token', 'StandardTagger', 'TreeTagger', 'Lemma', 'Label']]\n",
    "df_dev[\"TokenNR\"] = np.nan\n",
    "df_dev = df_dev.rename(columns={\"standard_tagger\": \"StandardTagger\"})\n",
    "df_dev = df_dev[['SentenceNR', 'TokenNR', 'Token', 'StandardTagger', 'TreeTagger', 'Lemma', 'Label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12d6969-38bb-4904-9306-0c97bcbbbbac",
   "metadata": {},
   "source": [
    "<br> with df.groupby(by = 'SentenceNR') the dataframe will be grouped according to the number of sentences.<br>\n",
    "And with the function enumerate_tokens the order of tokens in a sentence will also be supplemented to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71370b43-9b04-452d-aea8-2bdfbcf0ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_tokens(sentence):\n",
    "    c = 1\n",
    "    for index, row in sentence.iterrows():\n",
    "        sentence.at[index, 'TokenNR'] = c\n",
    "        c += 1\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28a208eb-daf3-4c77-b30f-8cc33ac4fc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.56 s, sys: 10 ms, total: 2.58 s\n",
      "Wall time: 2.58 s\n"
     ]
    }
   ],
   "source": [
    "%time df_dev = df_dev.groupby(by = 'SentenceNR', group_keys=True).apply(enumerate_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f922df34-b594-4a63-acbb-7b80a5d4d9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.8 s, sys: 124 ms, total: 24.9 s\n",
      "Wall time: 24.9 s\n"
     ]
    }
   ],
   "source": [
    "%time df_train = df_train.groupby(by = 'SentenceNR', group_keys=True).apply(enumerate_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6710ea31-4088-4642-8cbd-d3551c0fd603",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.TokenNR = df_train.TokenNR.astype(\"int64\")\n",
    "df_dev.TokenNR = df_dev.TokenNR.astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2f6a68c-1112-44d4-9346-68dca2acaec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.rename(columns={\"standard_tagger\": \"StandardTagger\"})\n",
    "df_train = df_train[['SentenceNR', 'TokenNR', 'Token', 'StandardTagger', 'TreeTagger', 'Lemma', 'Label']]\n",
    "df_dev = df_dev.rename(columns={\"standard_tagger\": \"StandardTagger\"})\n",
    "df_dev = df_dev[['SentenceNR', 'TokenNR', 'Token', 'StandardTagger', 'TreeTagger', 'Lemma', 'Label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf8c52-e751-4d3c-a751-20751fb3373e",
   "metadata": {},
   "source": [
    "<br>make copies of the train and dev dataframe so that the originals won't be changed in processing afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c71d951d-d0f2-4461-949e-8aa1c6fda3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_train.copy()\n",
    "dev = df_dev.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3510a54a-c931-4e84-bf1c-9b0faa279a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.rename(columns={\"SentenceNR\": \"Sent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "830ec2e3-d9be-4225-b7c1-e714a12b2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = dev.rename(columns={\"SentenceNR\": \"Sent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8608b88e-3c4c-4694-b26f-4d2f96fc52c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83f708d5-2c36-43cb-911b-4d3d2c896aa4",
   "metadata": {},
   "source": [
    "## Initialize three CountVectorizers with  train.Token,  train.StandardTagger  and  train.Lemma\n",
    "The <b>wf-, tf-, lf_vectorizer</b> convert three columns \"Token\", \"StandardTagger\" and \"Lemma\" to sparse matrix as foundations of the bigger feature (sparse) matrixes in the following steps. <br>\n",
    "In the step of context information these three vectorizers will also be applied to the context tokens around the original token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ff2b825-62ad-4d0d-9b8a-4ec15221bb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 928 ms, sys: 1 µs, total: 928 ms\n",
      "Wall time: 935 ms\n",
      "CPU times: user 77 ms, sys: 7 µs, total: 77 ms\n",
      "Wall time: 77.1 ms\n",
      "(349077, 7782) (37455, 7782)\n"
     ]
    }
   ],
   "source": [
    "# Token to spare Matrix\n",
    "wf_vectorizer = CountVectorizer(tokenizer=lambda x: (x,), lowercase=False, min_df=3)\n",
    "%time train_X_wf = wf_vectorizer.fit_transform(train.Token)\n",
    "%time dev_X_wf = wf_vectorizer.transform(dev.Token)\n",
    "print(train_X_wf.shape, dev_X_wf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f52aebf-0ccb-444a-bd13-d30cf6221270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 720 ms, sys: 3.25 ms, total: 724 ms\n",
      "Wall time: 724 ms\n",
      "CPU times: user 82.1 ms, sys: 0 ns, total: 82.1 ms\n",
      "Wall time: 82.3 ms\n",
      "(349077, 44) (37455, 44)\n"
     ]
    }
   ],
   "source": [
    "# Tag to spare Matrix\n",
    "tf_vectorizer = CountVectorizer(tokenizer=lambda x: (x,), lowercase=False, min_df=3)\n",
    "%time train_X_tf = tf_vectorizer.fit_transform(train.StandardTagger)\n",
    "%time dev_X_tf = tf_vectorizer.transform(dev.StandardTagger)\n",
    "print(train_X_tf.shape, dev_X_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8940c9b5-16b8-4a57-b2a2-543b78c64382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 774 ms, sys: 169 µs, total: 775 ms\n",
      "Wall time: 776 ms\n",
      "CPU times: user 92 ms, sys: 0 ns, total: 92 ms\n",
      "Wall time: 92.1 ms\n",
      "(349077, 5708) (37455, 5708)\n"
     ]
    }
   ],
   "source": [
    "# Lemma to spare Matrix\n",
    "lf_vectorizer = CountVectorizer(tokenizer=lambda x: (x,), lowercase=False, min_df=3)\n",
    "%time train_X_lf = lf_vectorizer.fit_transform(train.Lemma)\n",
    "%time dev_X_lf = lf_vectorizer.transform(dev.Lemma)\n",
    "print(train_X_lf.shape, dev_X_lf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5282d71d-fbd7-4953-85a0-532513fff31d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56ab6931-d96d-442b-8b7c-6264428c35fe",
   "metadata": {},
   "source": [
    "## Step 0\n",
    "## Basis Matrix: only with Token, Tag and Lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5219654-7a21-45cd-abc8-ac3517fa050a",
   "metadata": {},
   "source": [
    "to compare with the classification results of \"wider\" matrixes (matrixes with more columns) in the following steps. <br>\n",
    "All steps will use the same model: the <b>default LinearSVC</b> by sklearn. <br><br>\n",
    "<i>Special Attention:</i> <br>\n",
    "The \"outsider\" (\"o\") tokens, with makes up around 84% percent of all tokens, will be <b>excluded</b> from the classfication report, so that the result can concentrate on the named entity labels in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531898ff-ddb2-455d-b106-742d72a4b682",
   "metadata": {},
   "source": [
    "### Result: \n",
    "### weighted average for f1-score: 39% (dev), 44% (train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f16fab2-9ad4-455c-b18d-8b5ef16cbe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sp.sparse.hstack([train_X_wf, train_X_tf, train_X_lf])\n",
    "X_dev = sp.sparse.hstack([dev_X_wf, dev_X_tf, dev_X_lf])\n",
    "y_train = train[\"Label\"]\n",
    "y_dev = dev[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bab58ec0-f90e-4120-b2d2-67e5ce199d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ORG', 'I-ORG', 'B-OTHER_PERSON', 'I-OTHER_PERSON', 'B-WITNESS', 'I-WITNESS', 'B-GPE', 'B-STATUTE', 'B-DATE', 'I-DATE', 'B-PROVISION', 'I-PROVISION', 'I-STATUTE', 'B-COURT', 'I-COURT', 'B-PRECEDENT', 'I-PRECEDENT', 'B-CASE_NUMBER', 'I-CASE_NUMBER', 'I-GPE', 'B-PETITIONER', 'I-PETITIONER', 'B-JUDGE', 'I-JUDGE', 'B-RESPONDENT', 'I-RESPONDENT']\n"
     ]
    }
   ],
   "source": [
    "classes = train[\"Label\"].unique().tolist()\n",
    "classes.remove(\"o\")\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3841d2ad-9f7f-4f6c-8f9a-10f6168a43d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 27s, sys: 26.4 ms, total: 1min 27s\n",
      "Wall time: 1min 27s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC()\n",
    "%time svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "470ff5e3-fe6e-4db3-a4d5-cead24d27809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luxinyao/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         B-ORG       0.53      0.17      0.26       159\n",
      "         I-ORG       0.34      0.10      0.15       342\n",
      "B-OTHER_PERSON       0.35      0.15      0.21       276\n",
      "I-OTHER_PERSON       0.37      0.36      0.36       195\n",
      "     B-WITNESS       0.00      0.00      0.00        58\n",
      "     I-WITNESS       0.20      0.02      0.03        54\n",
      "         B-GPE       0.32      0.30      0.31       182\n",
      "     B-STATUTE       0.68      0.45      0.55       222\n",
      "        B-DATE       0.41      0.77      0.54       222\n",
      "        I-DATE       0.42      0.33      0.37       132\n",
      "   B-PROVISION       0.85      0.89      0.87       258\n",
      "   I-PROVISION       0.60      0.23      0.33       772\n",
      "     I-STATUTE       0.56      0.48      0.52       458\n",
      "       B-COURT       0.80      0.64      0.71       178\n",
      "       I-COURT       0.50      0.48      0.49       354\n",
      "   B-PRECEDENT       0.00      0.00      0.00       177\n",
      "   I-PRECEDENT       0.64      0.30      0.41      2223\n",
      " B-CASE_NUMBER       0.56      0.35      0.43       121\n",
      " I-CASE_NUMBER       0.38      0.26      0.31       381\n",
      "         I-GPE       0.42      0.11      0.17        47\n",
      "  B-PETITIONER       0.00      0.00      0.00         9\n",
      "  I-PETITIONER       0.00      0.00      0.00        11\n",
      "       B-JUDGE       0.00      0.00      0.00         8\n",
      "       I-JUDGE       0.09      0.14      0.11         7\n",
      "  B-RESPONDENT       0.00      0.00      0.00         5\n",
      "  I-RESPONDENT       0.00      0.00      0.00        12\n",
      "\n",
      "     micro avg       0.54      0.33      0.41      6863\n",
      "     macro avg       0.35      0.25      0.27      6863\n",
      "  weighted avg       0.53      0.33      0.39      6863\n",
      "\n",
      "CPU times: user 825 ms, sys: 3.32 ms, total: 828 ms\n",
      "Wall time: 834 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luxinyao/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/luxinyao/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "y_dev_pred = svc.predict(X_dev)\n",
    "print(classification_report(y_pred = y_dev_pred, y_true = y_dev, labels = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "58e37d6a-d556-4ce8-90e9-98a0d48f1b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         B-ORG       0.63      0.26      0.36      1441\n",
      "         I-ORG       0.55      0.21      0.30      2897\n",
      "B-OTHER_PERSON       0.49      0.33      0.40      2653\n",
      "I-OTHER_PERSON       0.40      0.54      0.46      2089\n",
      "     B-WITNESS       0.56      0.11      0.19       881\n",
      "     I-WITNESS       0.50      0.05      0.09       759\n",
      "         B-GPE       0.40      0.44      0.42      1395\n",
      "     B-STATUTE       0.80      0.62      0.70      1803\n",
      "        B-DATE       0.51      0.67      0.58      1885\n",
      "        I-DATE       0.48      0.32      0.39      1926\n",
      "   B-PROVISION       0.83      0.91      0.87      2384\n",
      "   I-PROVISION       0.65      0.29      0.40      6576\n",
      "     I-STATUTE       0.59      0.51      0.55      3802\n",
      "       B-COURT       0.79      0.64      0.70      1293\n",
      "       I-COURT       0.53      0.50      0.51      2804\n",
      "   B-PRECEDENT       0.45      0.06      0.11      1351\n",
      "   I-PRECEDENT       0.57      0.38      0.46     14098\n",
      " B-CASE_NUMBER       0.66      0.40      0.50      1039\n",
      " I-CASE_NUMBER       0.52      0.23      0.32      4043\n",
      "         I-GPE       0.45      0.08      0.14       284\n",
      "  B-PETITIONER       0.59      0.10      0.17       464\n",
      "  I-PETITIONER       0.65      0.05      0.08       377\n",
      "       B-JUDGE       0.65      0.28      0.39       567\n",
      "       I-JUDGE       0.63      0.23      0.34       397\n",
      "  B-RESPONDENT       0.77      0.07      0.14       324\n",
      "  I-RESPONDENT       0.42      0.04      0.07       452\n",
      "\n",
      "     micro avg       0.58      0.38      0.46     57984\n",
      "     macro avg       0.58      0.32      0.37     57984\n",
      "  weighted avg       0.58      0.38      0.44     57984\n",
      "\n",
      "CPU times: user 10.6 s, sys: 49.7 ms, total: 10.6 s\n",
      "Wall time: 10.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "y_train_pred = svc.predict(X_train)\n",
    "print(classification_report(y_pred = y_train_pred, y_true = y_train, labels = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605c187e-c41b-4dea-a2d9-bd5aff3838be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47e21fd0-9588-4cdf-98bf-2dd217870da8",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "## Will the prefixes and suffixes contribute to the model? --A small increase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd5aee3-9f68-4250-b1d8-137daee5610e",
   "metadata": {},
   "source": [
    "### Result: \n",
    "### weighted average for f1-score: 42% (dev), 50% (train), comparing to the basic model +3%, +6%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bac75cb-c96d-464d-8642-f48d52a7703c",
   "metadata": {},
   "source": [
    "### get_prefix_suffix:\n",
    "return all prefixes and suffixes in a token from the length of 2 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4063ab2-8194-40e9-a481-37e6d7575d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prefix_suffix(word):\n",
    "    l = len(word)\n",
    "    res = []\n",
    "    for k in range(2, 5):\n",
    "        if l > k:\n",
    "            res.append(\"-\" + word[-k:])\n",
    "    for k in range(2, 5):\n",
    "        if l > k:\n",
    "            res.append(word[:k] + \"-\")\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cac183e4-be13-4058-9cee-1efd58e76449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query ['-ry', '-ery', '-uery', 'qu-', 'que-', 'quer-']\n",
      "'due ['-ue', '-due', \"'d-\", \"'du-\"]\n"
     ]
    }
   ],
   "source": [
    "print(train.Token.tolist()[5], get_prefix_suffix(train.Token.tolist()[5]))\n",
    "print(dev.Token.tolist()[6], get_prefix_suffix(dev.Token.tolist()[6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2a1bd4-e549-4a10-835d-8805108c1595",
   "metadata": {},
   "source": [
    "<br> have a look at all affixes appearing more than 5000 times in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84d0667f-181c-473c-8a64-4e7e0d979b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luxinyao/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-al -as -at -ed -er -he -ing -ion -nd -ng -nt -on -tion an- co- no- re- th-\n"
     ]
    }
   ],
   "source": [
    "affix_vectorizer = CountVectorizer(tokenizer=get_prefix_suffix, min_df=5000)\n",
    "affix_vectorizer.fit(train.Token.tolist())\n",
    "print(\" \".join(affix_vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d336541-8007-427b-b7c2-ccd62f85d331",
   "metadata": {},
   "source": [
    "<br> For real usage we will set the min_df to a much lower number, to provide the model with more affix information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fede6cf8-b8b5-4fce-8d53-f0e453180163",
   "metadata": {},
   "outputs": [],
   "source": [
    "affix_vectorizer = CountVectorizer(tokenizer=get_prefix_suffix, min_df=20)\n",
    "train_X_affix = affix_vectorizer.fit_transform(train.Token.tolist())\n",
    "dev_X_affix = affix_vectorizer.transform(dev.Token.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c09a9033-fbc1-442d-9113-4fc492be99f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349077, 3976)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_affix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e39b74f1-da5b-4af5-b4dc-bec7dc80eafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37455, 3976)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_X_affix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153acd46-8063-4bff-b75d-2325117e45a9",
   "metadata": {},
   "source": [
    "<br> with sp.sparse.hstack combine the X_train from the last step with the new affixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8a3cfa5f-8de0-443d-b186-8d09eae36071",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = sp.sparse.hstack([X_train, train_X_affix])\n",
    "X1_dev = sp.sparse.hstack([X_dev, dev_X_affix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f2ce4b01-87ac-495b-b312-7f53f745c792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 30s, sys: 106 ms, total: 2min 30s\n",
      "Wall time: 2min 31s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC()\n",
    "%time clf.fit(X1_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "11b396be-6a7b-496b-bdfe-c73426b41310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         B-ORG       0.41      0.25      0.31       159\n",
      "         I-ORG       0.27      0.09      0.14       342\n",
      "B-OTHER_PERSON       0.30      0.38      0.34       276\n",
      "I-OTHER_PERSON       0.32      0.39      0.35       195\n",
      "     B-WITNESS       0.11      0.10      0.11        58\n",
      "     I-WITNESS       0.06      0.02      0.03        54\n",
      "         B-GPE       0.33      0.45      0.38       182\n",
      "     B-STATUTE       0.66      0.47      0.55       222\n",
      "        B-DATE       0.74      0.69      0.72       222\n",
      "        I-DATE       0.40      0.30      0.34       132\n",
      "   B-PROVISION       0.84      0.91      0.88       258\n",
      "   I-PROVISION       0.60      0.24      0.34       772\n",
      "     I-STATUTE       0.55      0.48      0.51       458\n",
      "       B-COURT       0.81      0.65      0.72       178\n",
      "       I-COURT       0.49      0.48      0.49       354\n",
      "   B-PRECEDENT       0.08      0.02      0.03       177\n",
      "   I-PRECEDENT       0.60      0.33      0.42      2223\n",
      " B-CASE_NUMBER       0.60      0.56      0.58       121\n",
      " I-CASE_NUMBER       0.37      0.34      0.35       381\n",
      "         I-GPE       0.35      0.13      0.19        47\n",
      "  B-PETITIONER       0.00      0.00      0.00         9\n",
      "  I-PETITIONER       0.00      0.00      0.00        11\n",
      "       B-JUDGE       0.05      0.25      0.08         8\n",
      "       I-JUDGE       0.06      0.14      0.09         7\n",
      "  B-RESPONDENT       0.50      0.20      0.29         5\n",
      "  I-RESPONDENT       0.00      0.00      0.00        12\n",
      "\n",
      "     micro avg       0.51      0.37      0.43      6863\n",
      "     macro avg       0.37      0.30      0.32      6863\n",
      "  weighted avg       0.52      0.37      0.42      6863\n",
      "\n",
      "CPU times: user 922 ms, sys: 6.59 ms, total: 929 ms\n",
      "Wall time: 930 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "y1_dev_pred = clf.predict(X1_dev)\n",
    "print(classification_report(y_pred = y1_dev_pred, y_true = y_dev, labels = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "65e5a590-bdf3-4d55-bbbf-77bb676cf31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         B-ORG       0.62      0.40      0.49      1441\n",
      "         I-ORG       0.57      0.26      0.36      2897\n",
      "B-OTHER_PERSON       0.49      0.63      0.55      2653\n",
      "I-OTHER_PERSON       0.41      0.65      0.51      2089\n",
      "     B-WITNESS       0.50      0.34      0.41       881\n",
      "     I-WITNESS       0.50      0.14      0.22       759\n",
      "         B-GPE       0.44      0.65      0.52      1395\n",
      "     B-STATUTE       0.80      0.65      0.72      1803\n",
      "        B-DATE       0.90      0.80      0.85      1885\n",
      "        I-DATE       0.48      0.33      0.39      1926\n",
      "   B-PROVISION       0.83      0.93      0.88      2384\n",
      "   I-PROVISION       0.67      0.30      0.41      6576\n",
      "     I-STATUTE       0.60      0.53      0.56      3802\n",
      "       B-COURT       0.79      0.65      0.71      1293\n",
      "       I-COURT       0.53      0.51      0.52      2804\n",
      "   B-PRECEDENT       0.49      0.17      0.25      1351\n",
      "   I-PRECEDENT       0.58      0.43      0.50     14098\n",
      " B-CASE_NUMBER       0.68      0.54      0.60      1039\n",
      " I-CASE_NUMBER       0.55      0.32      0.41      4043\n",
      "         I-GPE       0.54      0.16      0.24       284\n",
      "  B-PETITIONER       0.58      0.27      0.37       464\n",
      "  I-PETITIONER       0.63      0.14      0.23       377\n",
      "       B-JUDGE       0.66      0.51      0.57       567\n",
      "       I-JUDGE       0.63      0.35      0.45       397\n",
      "  B-RESPONDENT       0.72      0.18      0.29       324\n",
      "  I-RESPONDENT       0.59      0.13      0.21       452\n",
      "\n",
      "     micro avg       0.59      0.46      0.52     57984\n",
      "     macro avg       0.61      0.42      0.47     57984\n",
      "  weighted avg       0.60      0.46      0.50     57984\n",
      "\n",
      "CPU times: user 9.7 s, sys: 66.4 ms, total: 9.77 s\n",
      "Wall time: 9.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "y1_train_pred = clf.predict(X1_train)\n",
    "print(classification_report(y_pred = y1_train_pred, y_true = y_train, labels = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87993ee9-55bb-4a5c-b887-5f781ab0e1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21ba67d4-2daf-4ba5-a5c8-c0134145b548",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "## Will other features of the tokens contribute to the model? --Nothing changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640ac20e-b182-4bcd-b1e5-456916c746be",
   "metadata": {},
   "source": [
    "### Result: \n",
    "### weighted average for f1-score: 42% (dev), 51% (train), comparing to the basic model +3%, +7%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39948c3-7795-4752-b650-8f5a17efbf8e",
   "metadata": {},
   "source": [
    "Supossedly because the matrix already have pos tags and lemmas, other features of the tokens cannot help the model to learn better. <br>\n",
    "Since they don't make a difference, the other features won't be used in future steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7768d416-5658-48ee-927a-a0d34a213188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_other_features(df, test=False):\n",
    "    res = pd.DataFrame({\n",
    "        'upper': df.Token.str.match(r'[A-Z]'),\n",
    "        'allcaps': df.Token.str.fullmatch(r'[A-Z]+'),\n",
    "        'digits': df.Token.str.match(r'[0-9]'),\n",
    "        'alldigits': df.Token.str.fullmatch(r'-?[0-9][0-9.,]*'),\n",
    "        'noalpha': ~df.Token.str.contains(r'[a-z]', flags=re.IGNORECASE),\n",
    "        'noalnum': ~df.Token.str.contains(r'[0-9a-zäöü]', flags=re.IGNORECASE),\n",
    "        'atstart': df.TokenNR == 1,\n",
    "        'trunc': df.Token.str.endswith('-'),\n",
    "        'long': df.Token.str.len() >= 15,\n",
    "    })\n",
    "    if test:\n",
    "        return res\n",
    "    else:\n",
    "        return res.iloc[:, 1:].to_numpy(dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "94b07052-e5ba-477c-8fbc-909ef96f6cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 873 ms, sys: 3.24 ms, total: 876 ms\n",
      "Wall time: 877 ms\n",
      "CPU times: user 82.6 ms, sys: 0 ns, total: 82.6 ms\n",
      "Wall time: 82.7 ms\n"
     ]
    }
   ],
   "source": [
    "%time train_X_other = get_other_features(train)\n",
    "%time dev_X_other = get_other_features(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "34035c02-3e45-4f4c-a247-407b1e141df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train = sp.sparse.hstack([X_train, train_X_affix, train_X_other])\n",
    "X2_dev = sp.sparse.hstack([X_dev, dev_X_affix, dev_X_other])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "21cda032-5280-452c-bd67-92b8f89b8f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 29s, sys: 248 ms, total: 2min 29s\n",
      "Wall time: 2min 29s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC()\n",
    "%time svc.fit(X2_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "40164051-64d2-4a89-ad92-3e131e3cf93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         B-ORG       0.43      0.26      0.32       159\n",
      "         I-ORG       0.27      0.09      0.14       342\n",
      "B-OTHER_PERSON       0.30      0.36      0.33       276\n",
      "I-OTHER_PERSON       0.33      0.41      0.36       195\n",
      "     B-WITNESS       0.11      0.10      0.11        58\n",
      "     I-WITNESS       0.05      0.02      0.03        54\n",
      "         B-GPE       0.33      0.47      0.39       182\n",
      "     B-STATUTE       0.68      0.51      0.59       222\n",
      "        B-DATE       0.77      0.69      0.73       222\n",
      "        I-DATE       0.41      0.33      0.37       132\n",
      "   B-PROVISION       0.84      0.91      0.88       258\n",
      "   I-PROVISION       0.59      0.24      0.35       772\n",
      "     I-STATUTE       0.55      0.48      0.51       458\n",
      "       B-COURT       0.80      0.65      0.72       178\n",
      "       I-COURT       0.49      0.48      0.49       354\n",
      "   B-PRECEDENT       0.08      0.02      0.03       177\n",
      "   I-PRECEDENT       0.60      0.33      0.43      2223\n",
      " B-CASE_NUMBER       0.58      0.55      0.56       121\n",
      " I-CASE_NUMBER       0.38      0.34      0.35       381\n",
      "         I-GPE       0.38      0.13      0.19        47\n",
      "  B-PETITIONER       0.00      0.00      0.00         9\n",
      "  I-PETITIONER       0.00      0.00      0.00        11\n",
      "       B-JUDGE       0.07      0.38      0.11         8\n",
      "       I-JUDGE       0.11      0.29      0.16         7\n",
      "  B-RESPONDENT       0.50      0.20      0.29         5\n",
      "  I-RESPONDENT       0.00      0.00      0.00        12\n",
      "\n",
      "     micro avg       0.52      0.37      0.43      6863\n",
      "     macro avg       0.37      0.32      0.32      6863\n",
      "  weighted avg       0.52      0.37      0.42      6863\n",
      "\n",
      "CPU times: user 854 ms, sys: 0 ns, total: 854 ms\n",
      "Wall time: 854 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "y2_dev_pred = svc.predict(X2_dev)\n",
    "print(classification_report(y_pred = y2_dev_pred, y_true = y_dev, labels = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3eaf78e3-fad8-407a-aeeb-c1c5202e5d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         B-ORG       0.62      0.40      0.49      1441\n",
      "         I-ORG       0.57      0.26      0.36      2897\n",
      "B-OTHER_PERSON       0.49      0.63      0.55      2653\n",
      "I-OTHER_PERSON       0.42      0.66      0.51      2089\n",
      "     B-WITNESS       0.52      0.37      0.43       881\n",
      "     I-WITNESS       0.50      0.16      0.24       759\n",
      "         B-GPE       0.44      0.65      0.53      1395\n",
      "     B-STATUTE       0.81      0.65      0.72      1803\n",
      "        B-DATE       0.91      0.80      0.86      1885\n",
      "        I-DATE       0.48      0.34      0.40      1926\n",
      "   B-PROVISION       0.83      0.93      0.88      2384\n",
      "   I-PROVISION       0.67      0.31      0.42      6576\n",
      "     I-STATUTE       0.60      0.53      0.56      3802\n",
      "       B-COURT       0.79      0.65      0.71      1293\n",
      "       I-COURT       0.53      0.52      0.52      2804\n",
      "   B-PRECEDENT       0.49      0.17      0.25      1351\n",
      "   I-PRECEDENT       0.58      0.44      0.50     14098\n",
      " B-CASE_NUMBER       0.68      0.54      0.60      1039\n",
      " I-CASE_NUMBER       0.55      0.33      0.41      4043\n",
      "         I-GPE       0.54      0.16      0.25       284\n",
      "  B-PETITIONER       0.59      0.28      0.38       464\n",
      "  I-PETITIONER       0.63      0.14      0.23       377\n",
      "       B-JUDGE       0.67      0.53      0.60       567\n",
      "       I-JUDGE       0.65      0.39      0.49       397\n",
      "  B-RESPONDENT       0.74      0.19      0.30       324\n",
      "  I-RESPONDENT       0.58      0.12      0.20       452\n",
      "\n",
      "     micro avg       0.60      0.46      0.52     57984\n",
      "     macro avg       0.61      0.43      0.48     57984\n",
      "  weighted avg       0.60      0.46      0.51     57984\n",
      "\n",
      "CPU times: user 10.4 s, sys: 59.8 ms, total: 10.4 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "y2_train_pred = svc.predict(X2_train)\n",
    "print(classification_report(y_pred = y2_train_pred, y_true = y_train, labels = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5553f2b4-b31c-4434-b545-e3fdacd7d7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb0a8eaf-c8a1-446d-938c-a02bd8713193",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "## Context left and right: A great difference!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ade087-f472-4a9b-a5b9-ede4740de593",
   "metadata": {},
   "source": [
    "### Result: \n",
    "### weighted average for f1-score: 77% (dev), 94% (train), comparing to the basic model +38%, +50%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18283ad-9f0f-4196-be94-ecde876de53e",
   "metadata": {},
   "source": [
    "## add_context\n",
    "At first we will add new columns to the both dataframes. <br>\n",
    "The new columns show the tokens, tags and lemmas in the rows before and after.<br>\n",
    "<i>(2 words on the left and 2 words on the right in the original text)</i><br> <br>\n",
    "This process will be executed at the level of <b>each sentence</b> because the sentences are disjunctive in the dataframe. <br>\n",
    "In other words, \"neighbour\" sentences don't belong to the same judgement. They are randomly mixed. <br>\n",
    "Beginnings and ends of all sentences will be padded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8ab1df8-d949-4936-90bd-817014bdc9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_context(satz):\n",
    "    \n",
    "    satz[\"L1\"] = satz.Token.shift(1, fill_value=\"\")  \n",
    "    satz[\"L2\"] = satz.Token.shift(2, fill_value=\"\")  \n",
    "    satz[\"R1\"] = satz.Token.shift(-1, fill_value=\"\") \n",
    "    satz[\"R2\"] = satz.Token.shift(-2, fill_value=\"\") \n",
    "    \n",
    "    satz[\"posL1\"] = satz.StandardTagger.shift(1, fill_value=\"*\")\n",
    "    satz[\"posL2\"] = satz.StandardTagger.shift(2, fill_value=\"*\")\n",
    "    satz[\"posR1\"] = satz.StandardTagger.shift(-1, fill_value=\"*\")\n",
    "    satz[\"posR2\"] = satz.StandardTagger.shift(-2, fill_value=\"*\")\n",
    "    \n",
    "    satz[\"lemmaL1\"] = satz.Lemma.shift(1, fill_value=\"*\")\n",
    "    satz[\"lemmaL2\"] = satz.Lemma.shift(2, fill_value=\"*\")\n",
    "    satz[\"lemmaR1\"] = satz.Lemma.shift(-1, fill_value=\"*\")\n",
    "    satz[\"lemmaR2\"] = satz.Lemma.shift(-2, fill_value=\"*\")\n",
    "    \n",
    "    # Labels of two tokens before are just preparation for the trigramme model \n",
    "    satz[\"labelL1\"] = satz.Label.shift(1, fill_value=\"*\")\n",
    "    satz[\"labelL2\"] = satz.Label.shift(2, fill_value=\"*\")\n",
    "    \n",
    "    return satz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77eb019a-a604-462d-9f5c-8047555ee9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.9 s, sys: 319 ms, total: 54.2 s\n",
      "Wall time: 54.4 s\n",
      "CPU times: user 5.03 s, sys: 6.6 ms, total: 5.04 s\n",
      "Wall time: 5.05 s\n"
     ]
    }
   ],
   "source": [
    "%time train = train.groupby('Sent', group_keys=False).apply(add_context)\n",
    "%time dev = dev.groupby('Sent', group_keys=False).apply(add_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eea59f1-c1d4-4cae-b83b-c086222c5955",
   "metadata": {},
   "source": [
    "<br>Of course the last two columns (\"LabelL1\", \"LabelL2\")of dev are NOT allowed to be included in the feature matrix.<br>\n",
    "Otherwise they would lead to data leak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "671d7e5c-1503-4cfa-9efe-b70e01132cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Sent</th>\n",
       "      <th>TokenNR</th>\n",
       "      <th>Token</th>\n",
       "      <th>StandardTagger</th>\n",
       "      <th>TreeTagger</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Label</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>R1</th>\n",
       "      <th>...</th>\n",
       "      <th>posL1</th>\n",
       "      <th>posL2</th>\n",
       "      <th>posR1</th>\n",
       "      <th>posR2</th>\n",
       "      <th>lemmaL1</th>\n",
       "      <th>lemmaL2</th>\n",
       "      <th>lemmaR1</th>\n",
       "      <th>lemmaR2</th>\n",
       "      <th>labelL1</th>\n",
       "      <th>labelL2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SentenceNR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>NN</td>\n",
       "      <td>UH</td>\n",
       "      <td>true</td>\n",
       "      <td>o</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>,</td>\n",
       "      <td>...</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>,</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>,</td>\n",
       "      <td>our</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>our</td>\n",
       "      <td>...</td>\n",
       "      <td>NN</td>\n",
       "      <td>*</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>NNP</td>\n",
       "      <td>true</td>\n",
       "      <td>*</td>\n",
       "      <td>our</td>\n",
       "      <td>Constitution</td>\n",
       "      <td>o</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>our</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>PP$</td>\n",
       "      <td>our</td>\n",
       "      <td>o</td>\n",
       "      <td>,</td>\n",
       "      <td>True</td>\n",
       "      <td>Constitution</td>\n",
       "      <td>...</td>\n",
       "      <td>,</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>,</td>\n",
       "      <td>true</td>\n",
       "      <td>Constitution</td>\n",
       "      <td>have</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Constitution</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NP</td>\n",
       "      <td>Constitution</td>\n",
       "      <td>B-STATUTE</td>\n",
       "      <td>our</td>\n",
       "      <td>,</td>\n",
       "      <td>has</td>\n",
       "      <td>...</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>,</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>DT</td>\n",
       "      <td>our</td>\n",
       "      <td>,</td>\n",
       "      <td>have</td>\n",
       "      <td>no</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>has</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>VHZ</td>\n",
       "      <td>have</td>\n",
       "      <td>o</td>\n",
       "      <td>Constitution</td>\n",
       "      <td>our</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>DT</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Constitution</td>\n",
       "      <td>our</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>B-STATUTE</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">949</th>\n",
       "      <th>37450</th>\n",
       "      <td>949</td>\n",
       "      <td>10</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>o</td>\n",
       "      <td>root</td>\n",
       "      <td>behind</td>\n",
       "      <td>right</td>\n",
       "      <td>...</td>\n",
       "      <td>NN</td>\n",
       "      <td>IN</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NN</td>\n",
       "      <td>root</td>\n",
       "      <td>behind</td>\n",
       "      <td>right</td>\n",
       "      <td>ear</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37451</th>\n",
       "      <td>949</td>\n",
       "      <td>11</td>\n",
       "      <td>right</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>right</td>\n",
       "      <td>o</td>\n",
       "      <td>of</td>\n",
       "      <td>root</td>\n",
       "      <td>ear</td>\n",
       "      <td>...</td>\n",
       "      <td>IN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>of</td>\n",
       "      <td>root</td>\n",
       "      <td>ear</td>\n",
       "      <td>lobule</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37452</th>\n",
       "      <td>949</td>\n",
       "      <td>12</td>\n",
       "      <td>ear</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>ear</td>\n",
       "      <td>o</td>\n",
       "      <td>right</td>\n",
       "      <td>of</td>\n",
       "      <td>lobule</td>\n",
       "      <td>...</td>\n",
       "      <td>JJ</td>\n",
       "      <td>IN</td>\n",
       "      <td>NN</td>\n",
       "      <td>.</td>\n",
       "      <td>right</td>\n",
       "      <td>of</td>\n",
       "      <td>lobule</td>\n",
       "      <td>.</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37453</th>\n",
       "      <td>949</td>\n",
       "      <td>13</td>\n",
       "      <td>lobule</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>lobule</td>\n",
       "      <td>o</td>\n",
       "      <td>ear</td>\n",
       "      <td>right</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>NN</td>\n",
       "      <td>JJ</td>\n",
       "      <td>.</td>\n",
       "      <td>*</td>\n",
       "      <td>ear</td>\n",
       "      <td>right</td>\n",
       "      <td>.</td>\n",
       "      <td>*</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37454</th>\n",
       "      <td>949</td>\n",
       "      <td>14</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>SENT</td>\n",
       "      <td>.</td>\n",
       "      <td>o</td>\n",
       "      <td>lobule</td>\n",
       "      <td>ear</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>lobule</td>\n",
       "      <td>ear</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37455 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Sent  TokenNR         Token StandardTagger TreeTagger  \\\n",
       "SentenceNR                                                                \n",
       "1          0         1        1          True             NN         UH   \n",
       "           1         1        2             ,              ,          ,   \n",
       "           2         1        3           our           PRP$        PP$   \n",
       "           3         1        4  Constitution            NNP         NP   \n",
       "           4         1        5           has            VBZ        VHZ   \n",
       "...                ...      ...           ...            ...        ...   \n",
       "949        37450   949       10            of             IN         IN   \n",
       "           37451   949       11         right             JJ         JJ   \n",
       "           37452   949       12           ear             NN         NN   \n",
       "           37453   949       13        lobule             NN         NN   \n",
       "           37454   949       14             .              .       SENT   \n",
       "\n",
       "                         Lemma      Label            L1      L2            R1  \\\n",
       "SentenceNR                                                                      \n",
       "1          0              true          o                                   ,   \n",
       "           1                 ,          o          True                   our   \n",
       "           2               our          o             ,    True  Constitution   \n",
       "           3      Constitution  B-STATUTE           our       ,           has   \n",
       "           4              have          o  Constitution     our            no   \n",
       "...                        ...        ...           ...     ...           ...   \n",
       "949        37450            of          o          root  behind         right   \n",
       "           37451         right          o            of    root           ear   \n",
       "           37452           ear          o         right      of        lobule   \n",
       "           37453        lobule          o           ear   right             .   \n",
       "           37454             .          o        lobule     ear                 \n",
       "\n",
       "                  ... posL1 posL2 posR1 posR2       lemmaL1 lemmaL2  \\\n",
       "SentenceNR        ...                                                 \n",
       "1          0      ...     *     *     ,  PRP$             *       *   \n",
       "           1      ...    NN     *  PRP$   NNP          true       *   \n",
       "           2      ...     ,    NN   NNP   VBZ             ,    true   \n",
       "           3      ...  PRP$     ,   VBZ    DT           our       ,   \n",
       "           4      ...   NNP  PRP$    DT    JJ  Constitution     our   \n",
       "...               ...   ...   ...   ...   ...           ...     ...   \n",
       "949        37450  ...    NN    IN    JJ    NN          root  behind   \n",
       "           37451  ...    IN    NN    NN    NN            of    root   \n",
       "           37452  ...    JJ    IN    NN     .         right      of   \n",
       "           37453  ...    NN    JJ     .     *           ear   right   \n",
       "           37454  ...    NN    NN     *     *        lobule     ear   \n",
       "\n",
       "                       lemmaR1       lemmaR2    labelL1 labelL2  \n",
       "SentenceNR                                                       \n",
       "1          0                 ,           our          *       *  \n",
       "           1               our  Constitution          o       *  \n",
       "           2      Constitution          have          o       o  \n",
       "           3              have            no          o       o  \n",
       "           4                no             0  B-STATUTE       o  \n",
       "...                        ...           ...        ...     ...  \n",
       "949        37450         right           ear          o       o  \n",
       "           37451           ear        lobule          o       o  \n",
       "           37452        lobule             .          o       o  \n",
       "           37453             .             *          o       o  \n",
       "           37454             *             *          o       o  \n",
       "\n",
       "[37455 rows x 21 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26b229d-618a-4beb-b464-c943288e11c4",
   "metadata": {},
   "source": [
    "<br> Transform the tokens in the context with wf_vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09c01f36-09d6-43b8-952c-c1b9204c38d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.24 s, sys: 3.28 ms, total: 3.24 s\n",
      "Wall time: 3.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_token_context = sp.sparse.hstack([wf_vectorizer.transform(train.L1), \n",
    "                                        wf_vectorizer.transform(train.L2), \n",
    "                                        wf_vectorizer.transform(train.R1),\n",
    "                                        wf_vectorizer.transform(train.R2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba019c6d-a83e-4856-8342-a3d73f3a5bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349077, 31128)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_token_context.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4646ea9-e91a-4ebe-a76d-ce1b080502a6",
   "metadata": {},
   "source": [
    "<br> Transform the POS tags in the context with tf_vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "086ed4e1-da6a-4ddf-b62f-0974b309aca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.96 s, sys: 3.28 ms, total: 2.96 s\n",
      "Wall time: 2.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_tag_context = sp.sparse.hstack([tf_vectorizer.transform(train.posL1), \n",
    "                                        tf_vectorizer.transform(train.posL2), \n",
    "                                        tf_vectorizer.transform(train.posR1),\n",
    "                                        tf_vectorizer.transform(train.posR2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "243b17f0-dd27-413f-b880-c24179db3e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349077, 176)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tag_context.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197104fa-1423-49f3-9ac7-c462d59d3286",
   "metadata": {},
   "source": [
    "<br> Transform the lemmas in the context with lf_vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa8557e8-6777-4995-a4f0-62b71a11637d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.03 s, sys: 0 ns, total: 3.03 s\n",
      "Wall time: 3.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_lemma_context = sp.sparse.hstack([lf_vectorizer.transform(train.lemmaL1), \n",
    "                                        lf_vectorizer.transform(train.lemmaL2), \n",
    "                                        lf_vectorizer.transform(train.lemmaR1),\n",
    "                                        lf_vectorizer.transform(train.lemmaR2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f77ab6a-e914-47c5-94d9-e5b3a2a8f1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349077, 22832)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lemma_context.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7247339-3b9b-4c0b-ac2e-4de01cc59d23",
   "metadata": {},
   "source": [
    "<br> The same way for dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b59ffe8-1654-4de3-b7d9-540c13459393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 981 ms, sys: 0 ns, total: 981 ms\n",
      "Wall time: 983 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dev_token_context = sp.sparse.hstack([wf_vectorizer.transform(dev.L1), \n",
    "                                        wf_vectorizer.transform(dev.L2), \n",
    "                                        wf_vectorizer.transform(dev.R1),\n",
    "                                        wf_vectorizer.transform(dev.R2)])\n",
    "\n",
    "dev_tag_context = sp.sparse.hstack([tf_vectorizer.transform(dev.posL1), \n",
    "                                        tf_vectorizer.transform(dev.posL2), \n",
    "                                        tf_vectorizer.transform(dev.posR1),\n",
    "                                        tf_vectorizer.transform(dev.posR2)])\n",
    "\n",
    "dev_lemma_context = sp.sparse.hstack([lf_vectorizer.transform(dev.lemmaL1), \n",
    "                                        lf_vectorizer.transform(dev.lemmaL2), \n",
    "                                        lf_vectorizer.transform(dev.lemmaR1),\n",
    "                                        lf_vectorizer.transform(dev.lemmaR2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2a3ea5d1-adcc-41dc-bb94-73f15fc28996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349077, 67670)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3_train = sp.sparse.hstack([X_train, train_token_context, train_tag_context, train_lemma_context])\n",
    "X3_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "733a4d97-24b7-4a63-812b-3eee8ef0750c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37455, 67670)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3_dev = sp.sparse.hstack([X_dev, dev_token_context, dev_tag_context, dev_lemma_context])\n",
    "X3_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60087007-67ae-4400-9562-381eed0fd834",
   "metadata": {},
   "source": [
    "<br> At first we will simply provide the model with the +-2 context and their tags and lemmas to see its effect alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a86cd480-a5ad-4f3c-8e3d-718f8e16e379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.5 s, sys: 36.6 ms, total: 43.6 s\n",
      "Wall time: 43.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC()\n",
    "%time svc.fit(X3_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0f9ada6d-b420-4010-b029-aea5de60b2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         B-ORG       0.56      0.40      0.47       159\n",
      "         I-ORG       0.51      0.40      0.45       342\n",
      "B-OTHER_PERSON       0.76      0.57      0.65       276\n",
      "I-OTHER_PERSON       0.63      0.66      0.64       195\n",
      "     B-WITNESS       0.48      0.53      0.50        58\n",
      "     I-WITNESS       0.50      0.44      0.47        54\n",
      "         B-GPE       0.64      0.55      0.59       182\n",
      "     B-STATUTE       0.88      0.86      0.87       222\n",
      "        B-DATE       0.89      0.91      0.90       222\n",
      "        I-DATE       0.93      0.93      0.93       132\n",
      "   B-PROVISION       0.91      0.91      0.91       258\n",
      "   I-PROVISION       0.89      0.89      0.89       772\n",
      "     I-STATUTE       0.82      0.84      0.83       458\n",
      "       B-COURT       0.91      0.84      0.87       178\n",
      "       I-COURT       0.79      0.76      0.78       354\n",
      "   B-PRECEDENT       0.68      0.58      0.63       177\n",
      "   I-PRECEDENT       0.88      0.78      0.83      2223\n",
      " B-CASE_NUMBER       0.67      0.61      0.64       121\n",
      " I-CASE_NUMBER       0.69      0.80      0.74       381\n",
      "         I-GPE       0.50      0.55      0.53        47\n",
      "  B-PETITIONER       0.25      0.44      0.32         9\n",
      "  I-PETITIONER       0.20      0.36      0.26        11\n",
      "       B-JUDGE       0.30      0.88      0.45         8\n",
      "       I-JUDGE       0.46      0.86      0.60         7\n",
      "  B-RESPONDENT       0.05      0.20      0.08         5\n",
      "  I-RESPONDENT       0.06      0.08      0.07        12\n",
      "\n",
      "     micro avg       0.79      0.75      0.77      6863\n",
      "     macro avg       0.61      0.64      0.61      6863\n",
      "  weighted avg       0.80      0.75      0.77      6863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y3_dev_pred = svc.predict(X3_dev)\n",
    "print(classification_report(y_pred = y3_dev_pred, y_true = y_dev, labels = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "53ac3065-4d5d-4564-97e6-b2f14331a56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         B-ORG       0.93      0.88      0.90      1441\n",
      "         I-ORG       0.90      0.86      0.88      2897\n",
      "B-OTHER_PERSON       0.94      0.93      0.93      2653\n",
      "I-OTHER_PERSON       0.92      0.95      0.94      2089\n",
      "     B-WITNESS       0.96      0.89      0.92       881\n",
      "     I-WITNESS       0.95      0.91      0.93       759\n",
      "         B-GPE       0.94      0.91      0.93      1395\n",
      "     B-STATUTE       0.98      0.98      0.98      1803\n",
      "        B-DATE       0.98      0.98      0.98      1885\n",
      "        I-DATE       0.97      0.99      0.98      1926\n",
      "   B-PROVISION       0.98      0.99      0.98      2384\n",
      "   I-PROVISION       0.95      0.95      0.95      6576\n",
      "     I-STATUTE       0.97      0.97      0.97      3802\n",
      "       B-COURT       0.97      0.95      0.96      1293\n",
      "       I-COURT       0.95      0.92      0.93      2804\n",
      "   B-PRECEDENT       0.94      0.93      0.94      1351\n",
      "   I-PRECEDENT       0.92      0.93      0.93     14098\n",
      " B-CASE_NUMBER       0.95      0.92      0.93      1039\n",
      " I-CASE_NUMBER       0.91      0.89      0.90      4043\n",
      "         I-GPE       0.91      0.82      0.87       284\n",
      "  B-PETITIONER       0.98      0.87      0.92       464\n",
      "  I-PETITIONER       0.98      0.88      0.93       377\n",
      "       B-JUDGE       0.97      0.96      0.97       567\n",
      "       I-JUDGE       0.98      0.96      0.97       397\n",
      "  B-RESPONDENT       0.96      0.84      0.90       324\n",
      "  I-RESPONDENT       0.95      0.81      0.87       452\n",
      "\n",
      "     micro avg       0.94      0.93      0.94     57984\n",
      "     macro avg       0.95      0.92      0.93     57984\n",
      "  weighted avg       0.94      0.93      0.94     57984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y3_train_pred = svc.predict(X3_train)\n",
    "print(classification_report(y_pred = y3_train_pred, y_true = y_train, labels = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf8dc2f-e5f5-4427-867b-28be89e88c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bfb5bd0-4dc6-4ad8-b6a4-35d15d007485",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "## Context and Affix of context: Over training!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3041aec0-38cb-4787-b5ce-74915fb91ffa",
   "metadata": {},
   "source": [
    "### Result: \n",
    "### weighted average for f1-score: 77% (dev), 97% (train), comparing to the basic model +38%, +53%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891e0c77-8e28-4f6d-aebc-945f88ba39be",
   "metadata": {},
   "source": [
    "Comparing to the feature matrix with context but without affix of the contextes (last step, X3), <br>\n",
    "providing the model also the affix of contextes just leads to <b>an increased over training</b>, <br>\n",
    "but it brings nothing in predicting the dev dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bbc6c028-dbd9-44a3-ae3a-130e3c5d1da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.58 s, sys: 9.93 ms, total: 5.59 s\n",
      "Wall time: 5.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_affix_context = sp.sparse.hstack([affix_vectorizer.transform(train.L1.tolist()),\n",
    "                                       affix_vectorizer.transform(train.L2.tolist()),\n",
    "                                       affix_vectorizer.transform(train.R1.tolist()),\n",
    "                                       affix_vectorizer.transform(train.R2.tolist())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "eb07abf0-318d-47c1-ada7-26ed409ff471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 689 ms, sys: 2 µs, total: 689 ms\n",
      "Wall time: 689 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dev_affix_context = sp.sparse.hstack([affix_vectorizer.transform(dev.L1.tolist()),\n",
    "                                       affix_vectorizer.transform(dev.L2.tolist()),\n",
    "                                       affix_vectorizer.transform(dev.R1.tolist()),\n",
    "                                       affix_vectorizer.transform(dev.R2.tolist())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2bf7f5c2-79ff-438d-b0c3-56536f3ca41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X4_train = sp.sparse.hstack([X_train, train_X_affix, train_token_context, train_tag_context, train_lemma_context, train_affix_context])\n",
    "X4_dev = sp.sparse.hstack([X_dev, dev_X_affix, dev_token_context, dev_tag_context, dev_lemma_context, dev_affix_context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c8edc72b-ac21-4d61-a61f-de877d4e8f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349077, 87550)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X4_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "aeb83cde-90fa-4161-b29b-dc1354313e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37455, 87550)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X4_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ab8ac42d-9c78-42a7-b768-184c011f6ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 24s, sys: 440 ms, total: 1min 24s\n",
      "Wall time: 1min 24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luxinyao/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC()\n",
    "%time svc.fit(X4_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9260645f-0c34-4b9a-9e9f-e35294898a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         B-ORG       0.52      0.45      0.48       159\n",
      "         I-ORG       0.49      0.39      0.43       342\n",
      "B-OTHER_PERSON       0.73      0.61      0.66       276\n",
      "I-OTHER_PERSON       0.66      0.61      0.63       195\n",
      "     B-WITNESS       0.58      0.60      0.59        58\n",
      "     I-WITNESS       0.45      0.46      0.46        54\n",
      "         B-GPE       0.65      0.59      0.62       182\n",
      "     B-STATUTE       0.86      0.85      0.85       222\n",
      "        B-DATE       0.93      0.94      0.93       222\n",
      "        I-DATE       0.89      0.93      0.91       132\n",
      "   B-PROVISION       0.95      0.93      0.94       258\n",
      "   I-PROVISION       0.87      0.91      0.89       772\n",
      "     I-STATUTE       0.81      0.84      0.82       458\n",
      "       B-COURT       0.89      0.83      0.85       178\n",
      "       I-COURT       0.79      0.72      0.76       354\n",
      "   B-PRECEDENT       0.65      0.58      0.61       177\n",
      "   I-PRECEDENT       0.88      0.78      0.82      2223\n",
      " B-CASE_NUMBER       0.70      0.69      0.69       121\n",
      " I-CASE_NUMBER       0.69      0.86      0.77       381\n",
      "         I-GPE       0.50      0.49      0.49        47\n",
      "  B-PETITIONER       0.19      0.33      0.24         9\n",
      "  I-PETITIONER       0.18      0.27      0.21        11\n",
      "       B-JUDGE       0.33      0.88      0.48         8\n",
      "       I-JUDGE       0.50      1.00      0.67         7\n",
      "  B-RESPONDENT       0.00      0.00      0.00         5\n",
      "  I-RESPONDENT       0.06      0.17      0.09        12\n",
      "\n",
      "     micro avg       0.79      0.76      0.77      6863\n",
      "     macro avg       0.61      0.64      0.61      6863\n",
      "  weighted avg       0.79      0.76      0.77      6863\n",
      "\n",
      "CPU times: user 980 ms, sys: 3.29 ms, total: 984 ms\n",
      "Wall time: 985 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y4_dev_pred = svc.predict(X4_dev)\n",
    "print(classification_report(y_pred = y4_dev_pred, y_true = y_dev, labels = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "93351be2-120f-4ed2-ac07-d0aaaf546df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         B-ORG       0.96      0.96      0.96      1441\n",
      "         I-ORG       0.95      0.94      0.95      2897\n",
      "B-OTHER_PERSON       1.00      1.00      1.00      2653\n",
      "I-OTHER_PERSON       0.99      0.99      0.99      2089\n",
      "     B-WITNESS       1.00      1.00      1.00       881\n",
      "     I-WITNESS       1.00      0.99      1.00       759\n",
      "         B-GPE       0.98      0.98      0.98      1395\n",
      "     B-STATUTE       0.98      0.99      0.99      1803\n",
      "        B-DATE       0.99      1.00      1.00      1885\n",
      "        I-DATE       0.98      1.00      0.99      1926\n",
      "   B-PROVISION       0.99      0.99      0.99      2384\n",
      "   I-PROVISION       0.97      0.97      0.97      6576\n",
      "     I-STATUTE       0.98      0.99      0.99      3802\n",
      "       B-COURT       0.97      0.96      0.96      1293\n",
      "       I-COURT       0.97      0.96      0.96      2804\n",
      "   B-PRECEDENT       0.98      0.98      0.98      1351\n",
      "   I-PRECEDENT       0.96      0.97      0.96     14098\n",
      " B-CASE_NUMBER       0.98      0.97      0.98      1039\n",
      " I-CASE_NUMBER       0.96      0.95      0.96      4043\n",
      "         I-GPE       0.96      0.93      0.95       284\n",
      "  B-PETITIONER       0.99      0.99      0.99       464\n",
      "  I-PETITIONER       1.00      0.99      0.99       377\n",
      "       B-JUDGE       1.00      1.00      1.00       567\n",
      "       I-JUDGE       0.99      0.99      0.99       397\n",
      "  B-RESPONDENT       1.00      0.97      0.98       324\n",
      "  I-RESPONDENT       1.00      0.94      0.97       452\n",
      "\n",
      "     micro avg       0.97      0.97      0.97     57984\n",
      "     macro avg       0.98      0.98      0.98     57984\n",
      "  weighted avg       0.97      0.97      0.97     57984\n",
      "\n",
      "CPU times: user 10.9 s, sys: 73 ms, total: 11 s\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y4_train_pred = svc.predict(X4_train)\n",
    "print(classification_report(y_pred = y4_train_pred, y_true = y_train, labels = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f67303-2ead-46e0-9dcd-f889d5b6400d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a39b232-71e3-418d-8625-d47567c90860",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "## Context and only Affix of token itself: No improve, but over training reduced\n",
    "### Result: \n",
    "### weighted average for f1-score: 77% (dev), 95% (train), comparing to the basic model +38%, +51%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4f5718-8d82-46a4-a193-72148e1717aa",
   "metadata": {},
   "source": [
    "This time we remove the affix of contextes from the feature matrix. <br>\n",
    "Although it doesn't bring a better score for the dev, <br>\n",
    "but it reduced a little bit the over training as last time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b06bbb6f-4caf-4918-abca-7fe2e613014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X5_train = sp.sparse.hstack([X_train, train_X_affix, train_token_context, train_tag_context, train_lemma_context])\n",
    "X5_dev = sp.sparse.hstack([X_dev, dev_X_affix, dev_token_context, dev_tag_context, dev_lemma_context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "30636eae-a295-4f35-8955-e7c94ab79297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.7 s, sys: 46.5 ms, total: 56.7 s\n",
      "Wall time: 56.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC()\n",
    "%time svc.fit(X5_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "28914302-dab0-48a0-a0b5-906bea1e9880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         B-ORG       0.61      0.47      0.53       159\n",
      "         I-ORG       0.52      0.40      0.45       342\n",
      "B-OTHER_PERSON       0.72      0.61      0.66       276\n",
      "I-OTHER_PERSON       0.64      0.64      0.64       195\n",
      "     B-WITNESS       0.48      0.50      0.49        58\n",
      "     I-WITNESS       0.50      0.39      0.44        54\n",
      "         B-GPE       0.68      0.61      0.64       182\n",
      "     B-STATUTE       0.86      0.84      0.85       222\n",
      "        B-DATE       0.93      0.95      0.94       222\n",
      "        I-DATE       0.93      0.94      0.94       132\n",
      "   B-PROVISION       0.95      0.93      0.94       258\n",
      "   I-PROVISION       0.88      0.89      0.88       772\n",
      "     I-STATUTE       0.82      0.84      0.83       458\n",
      "       B-COURT       0.91      0.84      0.87       178\n",
      "       I-COURT       0.77      0.74      0.75       354\n",
      "   B-PRECEDENT       0.70      0.58      0.63       177\n",
      "   I-PRECEDENT       0.87      0.78      0.82      2223\n",
      " B-CASE_NUMBER       0.71      0.70      0.71       121\n",
      " I-CASE_NUMBER       0.68      0.82      0.75       381\n",
      "         I-GPE       0.44      0.51      0.47        47\n",
      "  B-PETITIONER       0.14      0.33      0.19         9\n",
      "  I-PETITIONER       0.25      0.45      0.32        11\n",
      "       B-JUDGE       0.29      0.75      0.41         8\n",
      "       I-JUDGE       0.47      1.00      0.64         7\n",
      "  B-RESPONDENT       0.06      0.20      0.09         5\n",
      "  I-RESPONDENT       0.04      0.08      0.05        12\n",
      "\n",
      "     micro avg       0.79      0.76      0.77      6863\n",
      "     macro avg       0.61      0.65      0.61      6863\n",
      "  weighted avg       0.80      0.76      0.77      6863\n",
      "\n",
      "CPU times: user 902 ms, sys: 3.29 ms, total: 905 ms\n",
      "Wall time: 906 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y5_dev_pred = svc.predict(X5_dev)\n",
    "print(classification_report(y_pred = y5_dev_pred, y_true = y_dev, labels = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "45fd9f4a-85f2-4414-b694-c7b87f520d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         B-ORG       0.95      0.94      0.94      1441\n",
      "         I-ORG       0.92      0.89      0.90      2897\n",
      "B-OTHER_PERSON       0.98      0.98      0.98      2653\n",
      "I-OTHER_PERSON       0.95      0.98      0.96      2089\n",
      "     B-WITNESS       0.98      0.96      0.97       881\n",
      "     I-WITNESS       0.98      0.94      0.96       759\n",
      "         B-GPE       0.97      0.96      0.97      1395\n",
      "     B-STATUTE       0.98      0.99      0.99      1803\n",
      "        B-DATE       0.99      1.00      0.99      1885\n",
      "        I-DATE       0.98      0.99      0.98      1926\n",
      "   B-PROVISION       0.98      0.99      0.99      2384\n",
      "   I-PROVISION       0.96      0.96      0.96      6576\n",
      "     I-STATUTE       0.98      0.97      0.98      3802\n",
      "       B-COURT       0.97      0.96      0.96      1293\n",
      "       I-COURT       0.95      0.93      0.94      2804\n",
      "   B-PRECEDENT       0.97      0.96      0.96      1351\n",
      "   I-PRECEDENT       0.94      0.94      0.94     14098\n",
      " B-CASE_NUMBER       0.96      0.94      0.95      1039\n",
      " I-CASE_NUMBER       0.92      0.91      0.92      4043\n",
      "         I-GPE       0.92      0.87      0.89       284\n",
      "  B-PETITIONER       0.99      0.97      0.98       464\n",
      "  I-PETITIONER       1.00      0.93      0.96       377\n",
      "       B-JUDGE       0.99      0.99      0.99       567\n",
      "       I-JUDGE       1.00      0.97      0.98       397\n",
      "  B-RESPONDENT       0.99      0.94      0.97       324\n",
      "  I-RESPONDENT       0.98      0.88      0.92       452\n",
      "\n",
      "     micro avg       0.96      0.95      0.95     57984\n",
      "     macro avg       0.97      0.95      0.96     57984\n",
      "  weighted avg       0.96      0.95      0.95     57984\n",
      "\n",
      "CPU times: user 10.2 s, sys: 56.5 ms, total: 10.3 s\n",
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y5_train_pred = svc.predict(X5_train)\n",
    "print(classification_report(y_pred = y5_train_pred, y_true = y_train, labels = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0215be48-37bd-49e7-a539-1a140c3b817d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7803c289-9e93-4eec-8fd2-506429945653",
   "metadata": {},
   "source": [
    "## Trigrame Processing: Even much worse than the basis matrix!\n",
    "### Result: \n",
    "### weighted average for f1-score: 25% (dev), comparing to the basic model -14%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e0c8bcb1-0c55-4140-a7ef-d5e77e250039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349077, 150)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_vectorizer = OneHotEncoder(handle_unknown = 'infrequent_if_exist', min_frequency=5)\n",
    "tmp_train = np.vstack([train.labelL1, train.labelL2, train.labelL2 + \" \" + train.labelL1]).T\n",
    "X_train_label = label_vectorizer.fit_transform(tmp_train)\n",
    "X_train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "10070b59-1039-4e44-a0a0-fa87c6588f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X6_train = sp.sparse.hstack([X_train, X_train_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0d87a434-d611-4653-bf5a-4a13de4ead9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.6 s, sys: 26.5 ms, total: 36.6 s\n",
      "Wall time: 36.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf = LinearSVC()\n",
    "clf.fit(X6_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6daeb510-f2d8-4c64-b4c5-f8f0e934db9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349077, 13684)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X6_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b73f9366-7038-42b1-abef-ed1fe2929244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349077, 150)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acfab4e-dcfc-4333-a63a-8f00d41add9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6e81ec45-f9ff-4f9f-a21b-51d8f81c9216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(satz):\n",
    "    return sp.sparse.hstack([\n",
    "        \n",
    "        sp.sparse.hstack([wf_vectorizer.transform(satz.Token)]),\n",
    "        tf_vectorizer.transform(satz.TreeTagger),\n",
    "        lf_vectorizer.transform(satz.Lemma),\n",
    "        \n",
    "        #wf_vectorizer.transform(satz.L1),\n",
    "        #wf_vectorizer.transform(satz.L2),\n",
    "        #wf_vectorizer.transform(satz.R1),\n",
    "        #wf_vectorizer.transform(satz.R2),\n",
    "        \n",
    "        #tf_vectorizer.transform(satz.posL1),\n",
    "        #tf_vectorizer.transform(satz.posL2),\n",
    "        #tf_vectorizer.transform(satz.posR1),\n",
    "        #tf_vectorizer.transform(satz.posR2),\n",
    "        \n",
    "        #lf_vectorizer.transform(satz.lemmaL1),\n",
    "        #lf_vectorizer.transform(satz.lemmaL2),\n",
    "        #lf_vectorizer.transform(satz.lemmaR1),\n",
    "        #lf_vectorizer.transform(satz.lemmaR2),\n",
    "    ], format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e8545d3a-6642-46c5-b19c-f3b9bde3bd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_sentence(satz):\n",
    "    n = satz.shape[0]\n",
    "    X = get_features(satz) # Matrix der Oberflächenmerkmale\n",
    "    tags = []\n",
    "    p1 = p2 = \"*\"          # vorhergehende Labels\n",
    "    for i in range(n):\n",
    "        x1 = X[i, :]\n",
    "        x2 = label_vectorizer.transform(np.array([[p1, p2, p2 + \" \" + p1]]))\n",
    "        x = sp.sparse.hstack([x1, x2])\n",
    "        tag = clf.predict(x)[0] # liefert NumPy-Array zurück\n",
    "        tags.append(tag)\n",
    "        p2, p1 = p1, tag\n",
    "    return pd.Series(tags, index=satz.index, dtype='string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e89b90-af3f-4a6f-a81a-760c602a382c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e8a250fb-5e68-480c-a08c-acc7b21b2e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32 s, sys: 29.9 ms, total: 32 s\n",
      "Wall time: 32.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predicted = dev.groupby('Sent').apply(tag_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "186db8f7-a48d-4d41-96b6-752a9fcea468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ORG', 'I-ORG', 'B-OTHER_PERSON', 'I-OTHER_PERSON', 'B-WITNESS', 'I-WITNESS', 'B-GPE', 'B-STATUTE', 'B-DATE', 'I-DATE', 'B-PROVISION', 'I-PROVISION', 'I-STATUTE', 'B-COURT', 'I-COURT', 'B-PRECEDENT', 'I-PRECEDENT', 'B-CASE_NUMBER', 'I-CASE_NUMBER', 'I-GPE', 'B-PETITIONER', 'I-PETITIONER', 'B-JUDGE', 'I-JUDGE', 'B-RESPONDENT', 'I-RESPONDENT']\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "17c56b5a-858d-4c9d-898a-22d701ed390a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luxinyao/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/luxinyao/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         B-ORG       0.70      0.04      0.08       159\n",
      "         I-ORG       0.00      0.00      0.00       342\n",
      "B-OTHER_PERSON       0.40      0.01      0.01       276\n",
      "I-OTHER_PERSON       0.00      0.00      0.00       195\n",
      "     B-WITNESS       0.00      0.00      0.00        58\n",
      "     I-WITNESS       0.00      0.00      0.00        54\n",
      "         B-GPE       0.00      0.00      0.00       182\n",
      "     B-STATUTE       0.77      0.19      0.31       222\n",
      "        B-DATE       0.37      0.74      0.50       222\n",
      "        I-DATE       0.75      0.34      0.47       132\n",
      "   B-PROVISION       0.87      0.83      0.85       258\n",
      "   I-PROVISION       0.94      0.70      0.80       772\n",
      "     I-STATUTE       0.56      0.05      0.09       458\n",
      "       B-COURT       0.92      0.60      0.72       178\n",
      "       I-COURT       0.86      0.32      0.47       354\n",
      "   B-PRECEDENT       0.17      0.01      0.01       177\n",
      "   I-PRECEDENT       0.83      0.02      0.03      2223\n",
      " B-CASE_NUMBER       0.65      0.25      0.36       121\n",
      " I-CASE_NUMBER       0.58      0.31      0.40       381\n",
      "         I-GPE       0.00      0.00      0.00        47\n",
      "  B-PETITIONER       0.00      0.00      0.00         9\n",
      "  I-PETITIONER       0.00      0.00      0.00        11\n",
      "       B-JUDGE       0.00      0.00      0.00         8\n",
      "       I-JUDGE       0.00      0.00      0.00         7\n",
      "  B-RESPONDENT       0.00      0.00      0.00         5\n",
      "  I-RESPONDENT       0.00      0.00      0.00        12\n",
      "\n",
      "     micro avg       0.73      0.21      0.33      6863\n",
      "     macro avg       0.36      0.17      0.20      6863\n",
      "  weighted avg       0.64      0.21      0.25      6863\n",
      "\n",
      "CPU times: user 1.01 s, sys: 3.15 ms, total: 1.02 s\n",
      "Wall time: 1.02 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luxinyao/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%time print(classification_report(y_pred=predicted, y_true=y_dev, labels = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca11828-79fa-481a-b7e7-44a19e6160ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91e01ad8-1a82-4bec-87c8-7024eda65c1a",
   "metadata": {},
   "source": [
    "## with data leak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f69ebc9-0185-4c02-a2a6-28b1028d5fbb",
   "metadata": {},
   "source": [
    "If we provide the dev matrix with basis matrix and the two \"gold\" Labels before, it will bring a surprisingly good result (84%). <br>\n",
    "Of course this couln'd be allowed in the tast. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "abf5192c-4ee0-421f-b1ec-130d265f5847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37455, 150)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_dev = np.vstack([dev.labelL1, dev.labelL2, dev.labelL2 + \" \" + dev.labelL1]).T\n",
    "X_dev_label = label_vectorizer.transform(tmp_dev)\n",
    "X_dev_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e1998c1b-91e0-47c8-96ad-610ffae3f77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X7_dev = sp.sparse.hstack([X_dev, X_dev_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "38ca9a35-1088-400a-8869-fc43f901d01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<37455x13684 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 219074 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X7_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a78e9993-4899-40e0-a7e0-69fcd375c6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         B-ORG       0.66      0.18      0.29       159\n",
      "         I-ORG       0.96      0.90      0.93       342\n",
      "B-OTHER_PERSON       0.58      0.27      0.37       276\n",
      "I-OTHER_PERSON       0.97      1.00      0.98       195\n",
      "     B-WITNESS       0.25      0.05      0.09        58\n",
      "     I-WITNESS       1.00      1.00      1.00        54\n",
      "         B-GPE       0.65      0.51      0.57       182\n",
      "     B-STATUTE       0.74      0.55      0.63       222\n",
      "        B-DATE       0.60      0.83      0.70       222\n",
      "        I-DATE       0.91      0.95      0.93       132\n",
      "   B-PROVISION       0.97      0.88      0.92       258\n",
      "   I-PROVISION       0.97      0.95      0.96       772\n",
      "     I-STATUTE       0.94      0.85      0.89       458\n",
      "       B-COURT       0.89      0.65      0.75       178\n",
      "       I-COURT       0.95      0.98      0.97       354\n",
      "   B-PRECEDENT       0.43      0.13      0.20       177\n",
      "   I-PRECEDENT       0.96      0.98      0.97      2223\n",
      " B-CASE_NUMBER       0.68      0.42      0.52       121\n",
      " I-CASE_NUMBER       0.90      0.99      0.94       381\n",
      "         I-GPE       0.87      1.00      0.93        47\n",
      "  B-PETITIONER       0.11      0.11      0.11         9\n",
      "  I-PETITIONER       1.00      1.00      1.00        11\n",
      "       B-JUDGE       0.18      0.25      0.21         8\n",
      "       I-JUDGE       1.00      1.00      1.00         7\n",
      "  B-RESPONDENT       0.00      0.00      0.00         5\n",
      "  I-RESPONDENT       1.00      0.67      0.80        12\n",
      "\n",
      "     micro avg       0.90      0.83      0.87      6863\n",
      "     macro avg       0.74      0.66      0.68      6863\n",
      "  weighted avg       0.88      0.83      0.84      6863\n",
      "\n",
      "CPU times: user 780 ms, sys: 3.32 ms, total: 784 ms\n",
      "Wall time: 783 ms\n"
     ]
    }
   ],
   "source": [
    "%time print(classification_report(y_pred=clf.predict(X7_dev), y_true=y_dev, labels = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65df3229-c2d3-4d0f-bb83-f4726867c1db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfaeb721-de15-4e8b-be33-7393d2902333",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save the best Feature Matrix X5\n",
    "Since the X5 sparse matrix with context and only affix of token itself provides the best result up to right now, we will save it for future uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3021ea3a-0943-4a13-aefe-51607c63ea79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f6f5f9bf-2410-4054-9729-56948ab6cfff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.73 s, sys: 19.8 ms, total: 2.75 s\n",
      "Wall time: 2.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scipy.sparse.save_npz('transitional_data/X5_train.npz', X5_train)\n",
    "X5_train = scipy.sparse.load_npz('transitional_data/X5_train.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1bd92a1-a85f-4f1b-a4c6-d8d47841e5fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 300 ms, sys: 8 µs, total: 300 ms\n",
      "Wall time: 300 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scipy.sparse.save_npz('transitional_data/X5_dev.npz', X5_dev)\n",
    "X5_dev = scipy.sparse.load_npz('transitional_data/X5_dev.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0584f500-3276-4046-9b7e-2ada0d8a9a69",
   "metadata": {},
   "source": [
    "<br>\n",
    "Also save the gold standards y_train, y_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aaf9c06e-0641-4f7e-aa38-b3d8e1d5e2db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(y_train)\n",
    "y_dev = pd.DataFrame(y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0270eaf0-f406-4766-8595-b971085e8dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.54 s, sys: 6.66 ms, total: 1.55 s\n",
      "Wall time: 1.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_train.to_csv(\"transitional_data/y_train.csv\", index=True)\n",
    "y_dev.to_csv(\"transitional_data/y_dev.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8233e12-7a56-4cc1-84c8-1c10454d2b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
